#!/usr/bin/env bash
set -euo pipefail

# Sync daemon for rclone replicated persistence
# Syncs configured paths to R2 cloud storage
# State stored in XDG-compliant directory (~/.local/state/coltec-persistence/)
#
# Supports both new (persistence.sync) and legacy (persistence.multi_scope_volumes) schemas

{# Normalize sync paths from either new or legacy schema -#}
{%- set sync_paths = [] -%}
{%- if persistence.sync is defined and persistence.sync -%}
  {#- New schema: persistence.sync list of SyncPath -#}
  {%- for sp in persistence.sync -%}
    {%- set _ = sync_paths.append({
      'name': sp.name,
      'path': sp.path,
      'remote_path': sp.remote_path,
      'direction': sp.direction | default('bidirectional'),
      'interval': sp.interval | default(300),
      'priority': sp.priority | default(2),
      'exclude': sp.exclude | default([])
    }) -%}
  {%- endfor -%}
{%- elif persistence.multi_scope_volumes is defined and persistence.multi_scope_volumes.environment is defined -%}
  {#- Legacy schema: persistence.multi_scope_volumes.environment list of RcloneVolumeConfig -#}
  {%- for vol in persistence.multi_scope_volumes.environment -%}
    {%- set _ = sync_paths.append({
      'name': vol.name,
      'path': vol.mount_path,
      'remote_path': vol.remote_path | default('workspaces/{org}/{project}/{env}/' ~ vol.name),
      'direction': vol.sync | default('bidirectional'),
      'interval': vol.interval | default(300),
      'priority': vol.priority | default(2),
      'exclude': vol.exclude | default([])
    }) -%}
  {%- endfor -%}
{%- endif %}

LOG_PREFIX="[sync-daemon]"

# XDG state directory for this workspace
XDG_STATE_HOME="${XDG_STATE_HOME:-$HOME/.local/state}"
STATE_DIR="${XDG_STATE_HOME}/coltec-persistence/${WORKSPACE_NAME:-unknown}"
BISYNC_STATE_DIR="${STATE_DIR}/bisync-state"
LOG_DIR="${STATE_DIR}/logs"
LOG_FILE="${LOG_DIR}/sync-daemon.log"

# Ensure state directories exist
mkdir -p "$BISYNC_STATE_DIR" "$LOG_DIR"

# Redirect all output to log file
exec > >(tee -a "$LOG_FILE") 2>&1

echo "${LOG_PREFIX} Starting rclone sync daemon at $(date)"
echo "${LOG_PREFIX} State directory: $STATE_DIR"
echo "${LOG_PREFIX} PID: $$"

# rclone configuration comes from environment variables
# If RCLONE_CONFIG_* vars aren't set, create them from the base secret vars
REMOTE_NAME="${RCLONE_REMOTE_NAME:-r2coltec}"
REMOTE_NAME_UPPER=$(echo "${REMOTE_NAME}" | tr '[:lower:]-' '[:upper:]_')

# Check if rclone config is already set (eval to work around bash indirect expansion)
TYPE_VAR_NAME="RCLONE_CONFIG_${REMOTE_NAME_UPPER}_TYPE"
eval "TYPE_VAR_VALUE=\${$TYPE_VAR_NAME:-}"

if [ -z "${TYPE_VAR_VALUE}" ]; then
    # Set up rclone config from base secret vars
    if [ -z "${S3_ACCESS_KEY_ID:-}" ] || [ -z "${S3_SECRET_ACCESS_KEY:-}" ] || [ -z "${JUICEFS_S3_ENDPOINT:-}" ]; then
        echo "${LOG_PREFIX} ERROR: Missing required environment variables"
        echo "${LOG_PREFIX} Need: S3_ACCESS_KEY_ID, S3_SECRET_ACCESS_KEY, JUICEFS_S3_ENDPOINT"
        exit 1
    fi

    echo "${LOG_PREFIX} Setting up rclone config environment variables..."
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_TYPE=s3"
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_PROVIDER=Cloudflare"
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_ACCESS_KEY_ID=${S3_ACCESS_KEY_ID}"
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_SECRET_ACCESS_KEY=${S3_SECRET_ACCESS_KEY}"
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_ENDPOINT=${JUICEFS_S3_ENDPOINT}"
    export "RCLONE_CONFIG_${REMOTE_NAME_UPPER}_REGION=auto"
fi

# Install yq if needed for YAML parsing
if ! command -v yq &> /dev/null; then
    echo "${LOG_PREFIX} Installing yq for YAML parsing..."
    sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
    sudo chmod +x /usr/local/bin/yq
fi

# Read configuration from environment (set in containerEnv by render_devcontainer)
# REMOTE_NAME already set above for rclone config
# RCLONE_BUCKET may be a full URL (https://bucket.account.r2.cloudflarestorage.com)
# Extract just the bucket name from the URL if needed
_raw_bucket="${RCLONE_BUCKET:-coltec-codespaces-data}"
if [[ "$_raw_bucket" == https://* ]]; then
    # Extract bucket name from URL: https://BUCKET.account.r2.cloudflarestorage.com -> BUCKET
    BUCKET=$(echo "$_raw_bucket" | sed -E 's|https://([^.]+)\..*|\1|')
else
    BUCKET="$_raw_bucket"
fi
ORG="${WORKSPACE_ORG:-unknown}"
PROJECT="${WORKSPACE_PROJECT:-unknown}"
ENV="${WORKSPACE_ENV:-unknown}"

echo "${LOG_PREFIX} Remote: ${REMOTE_NAME}, Bucket: ${BUCKET}"
echo "${LOG_PREFIX} Workspace: ${ORG}/${PROJECT}/${ENV}"

# Track last sync times
declare -A LAST_SYNC_TIME

# Check if bisync has been initialized for a volume
is_bisync_initialized() {
    local volume_name="$1"
    [ -f "${BISYNC_STATE_DIR}/${volume_name}.initialized" ]
}

# Mark bisync as initialized for a volume
mark_bisync_initialized() {
    local volume_name="$1"
    echo "$(date -Iseconds)" > "${BISYNC_STATE_DIR}/${volume_name}.initialized"
}

# Perform bisync with automatic resync on first run
# Args: volume_name mount_path remote_path [is_emergency] [exclude_args...]
do_bisync() {
    local volume_name="$1"
    local mount_path="$2"
    local remote_path="$3"
    local is_emergency="${4:-false}"
    shift 4 || shift $#
    local exclude_args=("$@")

    local remote_full="${REMOTE_NAME}:${BUCKET}/${remote_path}"

    if ! is_bisync_initialized "$volume_name"; then
        echo "${LOG_PREFIX}   First-time bisync for '$volume_name', running with --resync"
        # First run: use --resync to initialize bisync state
        if rclone bisync "$mount_path" "$remote_full" \
            --resync --max-delete 50 --fast-list "${exclude_args[@]}" 2>&1; then
            mark_bisync_initialized "$volume_name"
            echo "${LOG_PREFIX}   ✓ Initial bisync complete for '$volume_name'"
            return 0
        else
            echo "${LOG_PREFIX}   ⚠ Initial bisync failed for '$volume_name'"
            return 1
        fi
    else
        # Subsequent runs: normal bisync
        if rclone bisync "$mount_path" "$remote_full" \
            --max-delete 10 --fast-list "${exclude_args[@]}" 2>&1; then
            return 0
        else
            local exit_code=$?
            echo "${LOG_PREFIX}   ⚠ Bisync failed (exit $exit_code), checking if resync needed..."

            # Try resync as recovery
            if [ "$is_emergency" != "true" ]; then
                echo "${LOG_PREFIX}   Attempting recovery with --resync..."
                if rclone bisync "$mount_path" "$remote_full" \
                    --resync --max-delete 50 --fast-list "${exclude_args[@]}" 2>&1; then
                    echo "${LOG_PREFIX}   ✓ Recovery bisync complete for '$volume_name'"
                    return 0
                fi
            fi
            return 1
        fi
    fi
}

# Emergency sync function (triggered by SIGTERM/SIGINT)
emergency_sync() {
    echo ""
    echo "${LOG_PREFIX} ================================"
    echo "${LOG_PREFIX} EMERGENCY SYNC TRIGGERED at $(date)"
    echo "${LOG_PREFIX} ================================"

    local start_time=$(date +%s)
    local total_timeout=90  # Reserve 30s margin for 2-min SIGTERM window

    # Sync paths by priority (P1 first, then P2)
{% if sync_paths %}
{% for sp in sync_paths %}
{% if sp.priority == 1 %}
    # P1: {{ sp.name }}
    elapsed=$(($(date +%s) - start_time))
    if [ $elapsed -lt $total_timeout ]; then
        echo "${LOG_PREFIX}   [P1] Syncing '{{ sp.name }}' (${elapsed}s elapsed)..."
        timeout 30s rclone sync "{{ sp.path }}" "${REMOTE_NAME}:${BUCKET}/workspaces/${ORG}/${PROJECT}/${ENV}/{{ sp.name }}" \
            --fast-list --transfers 16 {% for pattern in sp.exclude %}--exclude '{{ pattern }}' {% endfor %}2>&1 \
            || echo "${LOG_PREFIX}   ⚠ P1 sync failed for '{{ sp.name }}'"
    fi
{% endif %}
{% endfor %}
{% for sp in sync_paths %}
{% if sp.priority == 2 or sp.priority == 3 %}
    # P{{ sp.priority }}: {{ sp.name }}
    elapsed=$(($(date +%s) - start_time))
    if [ $elapsed -lt $total_timeout ]; then
        echo "${LOG_PREFIX}   [P{{ sp.priority }}] Syncing '{{ sp.name }}' (${elapsed}s elapsed)..."
        timeout 30s rclone sync "{{ sp.path }}" "${REMOTE_NAME}:${BUCKET}/workspaces/${ORG}/${PROJECT}/${ENV}/{{ sp.name }}" \
            --fast-list --transfers 8 {% for pattern in sp.exclude %}--exclude '{{ pattern }}' {% endfor %}2>&1 \
            || echo "${LOG_PREFIX}   ⚠ P{{ sp.priority }} sync incomplete for '{{ sp.name }}'"
    fi
{% endif %}
{% endfor %}
{% endif %}

    local elapsed=$(($(date +%s) - start_time))
    echo "${LOG_PREFIX} Emergency sync complete (${elapsed}s total)"
    exit 0
}

# Register signal handlers
trap 'emergency_sync' SIGTERM SIGINT

# Main sync loop
echo "${LOG_PREFIX} Entering main sync loop (check interval: 60s)"

while true; do
    current_time=$(date +%s)

{% if sync_paths %}
{% for sp in sync_paths %}
    # Sync path: {{ sp.name }}
    {
        name="{{ sp.name }}"
        local_path="{{ sp.path }}"
        remote_path="workspaces/${ORG}/${PROJECT}/${ENV}/{{ sp.name }}"
        direction="{{ sp.direction }}"
        interval={{ sp.interval }}
        priority={{ sp.priority }}
        # Exclude patterns
        exclude_args=({% for pattern in sp.exclude %} --exclude '{{ pattern }}'{% endfor %})

        last_sync=${LAST_SYNC_TIME[$name]:-0}
        time_since_sync=$((current_time - last_sync))

        if [ $time_since_sync -ge $interval ]; then
            echo "${LOG_PREFIX} [P${priority}] Syncing '$name' (${time_since_sync}s since last sync)"

            if [ "$direction" == "bidirectional" ]; then
                if do_bisync "$name" "$local_path" "$remote_path" "false" "${exclude_args[@]}"; then
                    echo "${LOG_PREFIX}   ✓ Bidirectional sync complete for '$name'"
                    LAST_SYNC_TIME[$name]=$current_time
                else
                    echo "${LOG_PREFIX}   ⚠ Sync failed for '$name', will retry"
                fi
            elif [ "$direction" == "pull-only" ]; then
                if rclone sync "${REMOTE_NAME}:${BUCKET}/${remote_path}" "$local_path" --fast-list "${exclude_args[@]}" 2>&1; then
                    echo "${LOG_PREFIX}   ✓ Pull sync complete for '$name'"
                    LAST_SYNC_TIME[$name]=$current_time
                else
                    echo "${LOG_PREFIX}   ⚠ Pull sync failed for '$name', will retry"
                fi
            elif [ "$direction" == "push-only" ]; then
                if rclone sync "$local_path" "${REMOTE_NAME}:${BUCKET}/${remote_path}" --fast-list "${exclude_args[@]}" 2>&1; then
                    echo "${LOG_PREFIX}   ✓ Push sync complete for '$name'"
                    LAST_SYNC_TIME[$name]=$current_time
                else
                    echo "${LOG_PREFIX}   ⚠ Push sync failed for '$name', will retry"
                fi
            fi
        fi
    }
{% endfor %}
{% endif %}

    # Sleep for check interval (60s)
    sleep 60
done

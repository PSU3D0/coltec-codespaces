#!/usr/bin/env bash
set -euo pipefail

# Post-start script for devcontainer lifecycle
# Handles networking (Tailscale) and persistence (rclone replicated) setup

LOG_DIR=".devcontainer/logs"
mkdir -p "${LOG_DIR}"
LOG_FILE="${LOG_DIR}/post-start.log"

exec > >(tee -a "${LOG_FILE}") 2>&1

echo "[post-start] Starting services for {{ workspace_name }}..."

NETWORKING_ENABLED="${NETWORKING_ENABLED:-false}"
PERSISTENCE_ENABLED="${PERSISTENCE_ENABLED:-false}"
PERSISTENCE_MODE="${PERSISTENCE_MODE:-mounted}"
WORKSPACE_NAME="${WORKSPACE_NAME:-{{ workspace_name }}}"

# Helper to fail fast with a message
fail() {
  echo "[post-start] ERROR: $*" >&2
  exit 1
}

# 1) Networking (Tailscale)
if [[ "${NETWORKING_ENABLED}" == "true" ]]; then
  if [[ -z "${TAILSCALE_AUTH_KEY:-}" ]]; then
    fail "Networking enabled but TAILSCALE_AUTH_KEY is missing"
  fi

  HOSTNAME="${WORKSPACE_NAME}"
  echo "[post-start] Bringing up Tailscale as ${HOSTNAME}..."

  # Start tailscaled if not running
  if ! pgrep tailscaled >/dev/null; then
      echo "[post-start] Starting tailscaled..."
      # Use userspace networking to avoid /dev/net/tun issues unless explicit
      sudo tailscaled --tun=userspace-networking --socks5-server=localhost:1055 &
      sleep 3
  fi

  sudo tailscale up \
    --authkey="${TAILSCALE_AUTH_KEY}" \
    --hostname="${HOSTNAME}" \
    --ssh \
    --accept-dns=false \
    --advertise-tags="{{ networking.tags | join(',') if networking.tags else 'tag:devcontainer' }}" \
    || fail "tailscale up failed"

  sudo tailscale status || true
fi

# 2) Persistence (rclone replicated mode)
if [[ "${PERSISTENCE_ENABLED}" == "true" ]] && [[ "${PERSISTENCE_MODE}" == "replicated" ]]; then
  echo "[post-start] Configuring rclone for replicated persistence..."

  # Create XDG state directory for this workspace
  XDG_STATE_HOME="${XDG_STATE_HOME:-$HOME/.local/state}"
  STATE_DIR="${XDG_STATE_HOME}/coltec-persistence/${WORKSPACE_NAME}"
  mkdir -p "${STATE_DIR}/bisync-state" "${STATE_DIR}/logs"
  echo "[post-start] XDG state directory: ${STATE_DIR}"

  # Fix volume ownership - Docker volumes are created as root by default
  {% set volumes = persistence.multi_scope_volumes.environment if persistence.multi_scope_volumes is defined and persistence.multi_scope_volumes.environment is defined else [] %}
  {% if volumes %}
  echo "[post-start] Fixing volume ownership..."
  {% for volume in volumes %}
  if [ -d "{{ volume.mount_path }}" ]; then
    sudo chown -R vscode:vscode "{{ volume.mount_path }}" 2>/dev/null || true
    echo "[post-start]   ✓ Fixed ownership for {{ volume.mount_path }}"
  fi
  {% endfor %}
  {% else %}
  # Default persistence paths if not specified in template context
  for vol_path in /workspace/agent-context /workspace/scratch; do
    if [ -d "$vol_path" ]; then
      sudo chown -R vscode:vscode "$vol_path" 2>/dev/null || true
      echo "[post-start]   ✓ Fixed ownership for $vol_path"
    fi
  done
  {% endif %}

  # Run rclone-configure.sh to verify/setup rclone
  if [ -f ".devcontainer/scripts/rclone-configure.sh" ]; then
    echo "[post-start] Running rclone configuration..."
    bash .devcontainer/scripts/rclone-configure.sh
  else
    echo "[post-start] Warning: rclone-configure.sh not found, skipping configuration"
  fi

  # Start sync daemon in background
  if [ -f ".devcontainer/scripts/sync-daemon.sh" ]; then
    echo "[post-start] Starting rclone sync daemon..."

    # Make script executable
    chmod +x .devcontainer/scripts/sync-daemon.sh

    # Start daemon in background
    # The daemon will use XDG state directory for logs and bisync state
    nohup bash .devcontainer/scripts/sync-daemon.sh > /dev/null 2>&1 &
    DAEMON_PID=$!

    echo "[post-start] Sync daemon started (PID: $DAEMON_PID)"

    # Save PID for potential cleanup (in XDG state dir)
    echo "$DAEMON_PID" > "${STATE_DIR}/sync-daemon.pid"
  else
    echo "[post-start] Warning: sync-daemon.sh not found, skipping sync daemon"
  fi
fi

echo "[post-start] Done."
